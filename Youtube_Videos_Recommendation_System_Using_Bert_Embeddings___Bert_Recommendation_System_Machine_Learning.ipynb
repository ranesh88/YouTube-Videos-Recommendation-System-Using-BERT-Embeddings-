{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOnCAglsveWc4gnVyZglFrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranesh88/YouTube-Videos-Recommendation-System-Using-BERT-Embeddings-/blob/main/Youtube_Videos_Recommendation_System_Using_Bert_Embeddings___Bert_Recommendation_System_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSXvbCdbZfIN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import torch\n",
        "import re\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "Ky6kIR4kZf4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWdoGCy8Zf7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "df_yt = pd.read_csv('/content/US_videos_data.csv')\n",
        "df_yt = df_yt[['title','channelTitle','likes','dislikes','thumbnail_link','description']]\n",
        "df_yt.head()"
      ],
      "metadata": {
        "id": "psiFbntzZf-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-uUHvfeZgBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_yt.shape"
      ],
      "metadata": {
        "id": "fhxpxPplZgEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVX603aJZgG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate titles\n",
        "df_yt = df_yt.drop_duplicates(subset=['title'])"
      ],
      "metadata": {
        "id": "Ohqn_ZR_ZgJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_yt.isnull().sum()"
      ],
      "metadata": {
        "id": "RbXs2TrBZgMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_yt.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "7Lf_tufIZgPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gN2lZaEzZgSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_yt['clean_title'] = df_yt['title'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x) if isinstance(x, str) else '')"
      ],
      "metadata": {
        "id": "YdxA0EcaZgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkwthTK7ZgXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Hugging Face BERT tokenizer and model for TensorFlow\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "2hWJRiIMZgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5u-bxbfjZgdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_embeddings(text, tokenizer, model):\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Use the Hugging Face TFBertModel to get the embeddings\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Return the pooled output (embedding for the [CLS] token)\n",
        "    return outputs.pooler_output.numpy()\n",
        "\n",
        "# Apply the function to each cleaned title in the DataFrame\n",
        "df_yt['embeddings'] = df_yt['clean_title'].apply(lambda x: get_bert_embeddings(x, tokenizer, model))"
      ],
      "metadata": {
        "id": "Nyp9zLEAb5PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSTQDzmEb5Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIXYt_SMb5VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_yt.head()"
      ],
      "metadata": {
        "id": "eDHi2v-xb5YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save final df\n",
        "df_yt.to_csv('final_df.csv', index=False)"
      ],
      "metadata": {
        "id": "flUwCJPMb5a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aFhwt48lb5d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6TP4fIJ0EVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def compute_cosine_similarity(embedding, embeddings):\n",
        "    \"\"\"\n",
        "    Compute cosine similarity between a single embedding and all other embeddings.\n",
        "\n",
        "    Args:\n",
        "    - embedding (np.ndarray): The embedding vector for the input title.\n",
        "    - embeddings (list of np.ndarray): List of all embedding vectors in the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - similarities (np.ndarray): Array of cosine similarities.\n",
        "    \"\"\"\n",
        "    similarities = cosine_similarity(embedding.reshape(1, -1), np.vstack(embeddings)).flatten()\n",
        "    return similarities\n",
        "\n",
        "def recommend_videos(title, df, tokenizer, model, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommend top N similar videos based on the embeddings of the cleaned titles.\n",
        "\n",
        "    Args:\n",
        "    - title (str): The title of the video for which we want to find similar videos.\n",
        "    - df (pd.DataFrame): DataFrame containing video data and embeddings.\n",
        "    - tokenizer (BertTokenizer): Hugging Face tokenizer.\n",
        "    - model (TFBertModel): Hugging Face BERT model.\n",
        "    - top_n (int): Number of similar videos to recommend.\n",
        "\n",
        "    Returns:\n",
        "    - recommendations (pd.DataFrame): DataFrame of recommended videos.\n",
        "    \"\"\"\n",
        "    # Preprocess and get the embedding for the input title\n",
        "    cleaned_title = re.sub('[^A-Za-z0-9]+', ' ', title.lower())\n",
        "    embedding = get_bert_embeddings(cleaned_title, tokenizer, model)\n",
        "\n",
        "    # Compute similarities between the input embedding and all other embeddings\n",
        "    similarities = compute_cosine_similarity(embedding, df['embeddings'].tolist())\n",
        "\n",
        "    # Add the similarity scores to the DataFrame\n",
        "    df['similarity'] = similarities\n",
        "\n",
        "    # Sort the DataFrame based on similarity scores in descending order\n",
        "    df_sorted = df.sort_values(by='similarity', ascending=False)\n",
        "\n",
        "    # Return the top N recommendations (excluding the input title itself if it's present)\n",
        "    recommendations = df_sorted[df_sorted['title'] != title].head(top_n)\n",
        "\n",
        "    return recommendations[['title', 'channelTitle','likes','dislikes','thumbnail_link', 'similarity']]"
      ],
      "metadata": {
        "id": "49QQbhh40EaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "import pandas as pd\n",
        "\n",
        "def display_recommendations(recommendations):\n",
        "    # Generate HTML for displaying thumbnails and metadata\n",
        "    html = '<div style=\"display: flex; flex-wrap: wrap; justify-content: space-around;\">'\n",
        "\n",
        "    # Iterate over recommendations in pairs (2 thumbnails per row)\n",
        "    for i in range(0, len(recommendations), 2):\n",
        "        row_html = '<div style=\"display: flex; justify-content: space-around; width: 100%;\">'\n",
        "\n",
        "        # Iterate through each item in the pair (2 thumbnails per row)\n",
        "        for j in range(2):\n",
        "            if i + j < len(recommendations):\n",
        "                # Fetch data for each recommendation\n",
        "                recommendation = recommendations.iloc[i + j]\n",
        "                title = recommendation['title']\n",
        "                thumbnail = recommendation['thumbnail_link']\n",
        "                likes = recommendation['likes']\n",
        "                dislikes = recommendation['dislikes']\n",
        "                similarity = recommendation['similarity']\n",
        "                channelTitle = recommendation['channelTitle']\n",
        "\n",
        "                # Generate HTML for each video thumbnail and details\n",
        "                row_html += f'''\n",
        "                <div style=\"width: 20%; margin: 2px; text-align: center; border: 1px solid #ddd; padding: 2px; border-radius: 10px;\">\n",
        "                    <img src=\"{thumbnail}\" alt=\"{title}\" style=\"width: 100%; border-radius: 5px;\">\n",
        "                    <h4>{title}</h4>\n",
        "                    <p>Channel: {channelTitle}</p>\n",
        "                    <p>Likes: {likes} | Dislikes: {dislikes}</p>\n",
        "                    <p>Similarity: {similarity:.2f}</p>\n",
        "                </div>\n",
        "                '''\n",
        "        row_html += '</div>'\n",
        "        html += row_html\n",
        "\n",
        "    html += '</div>'\n",
        "    display(HTML(html))"
      ],
      "metadata": {
        "id": "ClnM7wiq0Eey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "title_to_recommend = input(\"Your Input Video Title Here : \")\n",
        "top_recommendations = recommend_videos(title_to_recommend, df_yt, tokenizer, model, top_n=10)\n",
        "\n",
        "# Display the recommendations\n",
        "display_recommendations(top_recommendations)"
      ],
      "metadata": {
        "id": "6dsQh2aH0Ejk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "title_to_recommend = input(\"Your Input Video Title Here\")\n",
        "top_recommendations = recommend_videos(title_to_recommend, df_yt, tokenizer, model, top_n=10)\n",
        "\n",
        "# Display the recommendations\n",
        "display_recommendations(top_recommendations)"
      ],
      "metadata": {
        "id": "55Nv8uVv0Eoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFXNam7NZgg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}